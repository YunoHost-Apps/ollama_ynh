#:schema https://raw.githubusercontent.com/YunoHost/apps/main/schemas/manifest.v2.schema.json

packaging_format = 2

id = "ollama"
name = "Ollama"
description.en = "Get up and running with large language models"

version = "0.12.7~ynh1"

maintainers = ["Thovi98"]

[upstream]
license = "MIT"
website = "https://ollama.com/"
code = "https://github.com/ollama/ollama"
cpe = "cpe:2.3:a:ollama:ollama"

[integration]
yunohost = ">= 12.0.9"
helpers_version = "2.1"
architectures = "all"
multi_instance = false

ldap = false
sso = false

disk = "2G"
ram.build = "50M"
ram.runtime = "4G"

[install]
    [install.domain]
    type = "domain"

    [install.init_main_permission]
    type = "group"
    default = "visitors"

[resources]

    [resources.sources]

    [resources.sources.main]

    amd64.url = "https://github.com/ollama/ollama/releases/download/v0.12.7/ollama-linux-amd64.tgz"
    amd64.sha256 = "b59bd263c8888c1e09e5054b16030ad052f8edd3dbf6be4b4c9ab5ee422ea04f"
    
    arm64.url = "https://github.com/ollama/ollama/releases/download/v0.12.7/ollama-linux-arm64.tgz"
    arm64.sha256 = "b3659bded1d29a0d0e344b6b578d60215e06f4d524cdd1d2c6ba3d595c9987f4"
    
    in_subdir = false

    autoupdate.strategy = "latest_github_release"
    autoupdate.asset.amd64 = ".*linux-amd64.tgz"
    autoupdate.asset.arm64 = ".*linux-arm64.tgz"

    [resources.system_user]

    [resources.install_dir]

    [resources.data_dir]
    subdirs = ["models"]

    [resources.permissions]
    main.url = "/"

    [resources.ports]
    main.default = 11434
    main.fixed = true
